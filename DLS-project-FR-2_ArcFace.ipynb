{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dukei/dls-fr/blob/master/DLS-project-FR-2_ArcFace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-tZoxywJ1I0"
      },
      "source": [
        "# ArcFace Loss (Additive Angular Margin Loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKGDNGvnrrNC"
      },
      "source": [
        "## Теория ArcFace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R70bm-ayJznN"
      },
      "source": [
        "В случае с обучением на задачу классификации первая подходящая лосс-функция, которая нам приходит в голову — Cross-Entropy. И на ней действительно можно обучать сеть для распознавания лиц. Но за много лет люди придумали более хитрые трюки, которые делают обучение сети для распознавания лиц более эффективным. Одним из лучших подходов считается ArcFace (Additive Angular Margin).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5N_BHHSK1JR"
      },
      "source": [
        "**Как устроен ArcFace**:\n",
        "\n",
        "Стандартные SoftMax + кросс-энтропия (CE) выглядят так:\n",
        "\n",
        "$$L_{CE} = \\frac{-1}{N}\\sum_1^N \\frac{e^{W_{y_i}^{T}x_i + b_{y_i}}}{\\sum^n_{j=1}e^{W_j^Tx_i+b_j}},$$\n",
        "\n",
        "здесь:\n",
        "- $x_i \\in \\mathbb{R^d}$ — вектор $i$-го элемента обучающей выборки перед последним полносвязным слоем сети. $y_i$ — класс этого элемента;\n",
        "- $W_j \\in \\mathbb{R^d}$ — j-ый столбец матрицы весов последнего слоя сети (т.е. слоя, который производит итоговую классификацю входящего объекта);\n",
        "- $b_j \\in \\mathbb{R^d}$ — j-ый элемент вектора байеса последнего слоя сети;\n",
        "- $N$ — batch size;\n",
        "- $n$ — количество классов.\n",
        "\n",
        "\n",
        "Хотя этот лосс работает хорошо, он явным образом не заставляет эмбеддинги $x_i$ элементов, принадлежащих одному классу, быть близкими друг к другу по расстоянию. И не заставляет эмбеддинги элементов, принадлежащих разным классам, быть далеко друг от друга. Все, что хочет этот лосс — чтобы на основе эмбеддингов $x_i$ можно было хорошо классифицировать элементы, никакие ограничений на расстояния между эмбеддингами $x_i$ он не вводит.\n",
        "\n",
        "Из-за этого у нейросетей для распознавания лиц, которые обучены на обычном CE loss, бывают проблемы с распознаванием лиц, которые сильно отличаются от лиц того же человека разными доп. атрибутами (шляпа/прическа/очки и т.п.). Просто эмбеддинг для таких лиц получается довольно далек по расстоянию от других эмбеддингов лиц этого же человека.\n",
        "\n",
        "Давайте теперь немного поправим формулу:\n",
        "- уберем байес последнего слоя, т.е. сделаем $b_j=0$;\n",
        "- нормализуем веса последнего слоя: ||$W_j$|| = 1;\n",
        "- нормализуем эмбеддинги: ||$x_i$|| = 1. Перед подачей их на вход последнему слою (т.е. перед умножением на матрицу $W_j$) умножим их на гиперпараметр s. По сути, мы приводим норму всех эмбеддингов к s. Смысл этого гиперпараметра в том, что, возможно, сети проще будет классифицировать эмбеддинги, у которых не единичная норма.\n",
        "\n",
        "Нормализация приводит к тому, что эмбеддинги распределяются по сфере единичного радиуса (и сфере радиуса s после умножения на гиперпараметр s). И итоговые предсказания сети после последнего слоя зависят только от угла между эмбеддингами $x_i$ и выученных весов $W_j$. От нормы эмбеддинга $x_i$ они больше не зависят, т.к. у всех эмбеддингов они теперь одинаковые.\n",
        "\n",
        "Получается, в степени экспоненты у нас останется выражение $s W_{y_i}^{T}x_i$, которое можно переписать в виде  $s W_{y_i}^{T}x_i = s ||W_{y_i}||\\cdot ||x_i|| \\cdot cos\\Theta_{y_i}$. Тут $\\Theta_{y_i}$ — это угол между векторами $W_{y_i}$ и $x_i$. Но так как мы сделали нормы $W_{y_i}$ и $x_i$ единичными, то все это выражение просто будет равно $s cos\\Theta_{y_i}$.\n",
        "\n",
        "В итоге мы получим следующую формулу лосса:\n",
        "\n",
        "$$L = \\frac{-1}{N}\\sum_1^N \\frac{e^{s\\ cos\\Theta_{y_i}}}{e^{s\\ cos\\Theta_{y_i}} + \\sum^n_{j=1,\\ j\\ne y_i} e^{s\\ cos\\Theta_j}}$$\n",
        "\n",
        "\n",
        "И последний шаг. Добавим еще один гиперпараметр $m$. Он называется additive angular margin penalty и заставляет эмбеддинги одного класса быть ближе друг к другу, а эмбеддинги разных классов — более далекими друг от друга.\n",
        "\n",
        "В итоге получим вот что:\n",
        "\n",
        "$$L_{ArcFace} = \\frac{-1}{N}\\sum_1^N \\frac{e^{s\\ cos(\\Theta_{y_i} + m)}}{e^{s\\ cos(\\Theta_{y_i} + m)} + \\sum^n_{j=1,\\ j\\ne y_i} e^{s\\ cos\\Theta_j}}$$\n",
        "\n",
        "Это и есть ArcFace Loss с двумя  гиперпараметрами, s и m.\n",
        "\n",
        "Получается, что ArcFace Loss завтавляет сеть выучивать эмбеддинги, распределенные по сфере радиуса s, причем чтобы эмбеддинги одного класса были ближе друг к другу, а эмбеддинги разных классов — более далеки друг от друга.\n",
        "\n",
        "![ArcFace](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTKRR-YA_XR3yhIYBbkc8Zlbua0Q2WdM3gx_g&s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EI80vHxcRo4u"
      },
      "source": [
        "**Важное пояснение:**\n",
        "\n",
        "Строго говоря, ArcFace - не лосс, отдельный архитектурный модуль модификация SoftMax. Он реализует идею внесения геометрического отступа непосредственно в пространство признаков. Для обучения в качестве лосса используется обычная кросс-энтропия. Более конкретно по шагам:\n",
        "\n",
        "1. Вы извлекаете эмбеддинги из бэкбона сети (предобученной модели, у которой обрезан FC-слой, если он был)\n",
        "2. Эти эмбеддинги поступают в ArcFace-слой, который содержит векторы-центры для каждого класса (веса классификатора) и логику нормализации и добавления углового отступа\n",
        "3. Для целевого класса ArcFace-слой преобразует косинус угла $\\theta$ в $cos(\\theta + m)$\n",
        "4. Для остальных классов оставляет обычный косинус $cos(\\theta)$\n",
        "5. Эти модифицированные логиты подаются на вход стандартной функции Cross-Entropy\n",
        "6. Градиенты от Cross-Entropy текут назад через ArcFace-слой к бэкбону, обучая модель извлекать эмбеддинги\n",
        "\n",
        "Результат: модифицированные логиты с \"жестким\" разделением для целевого класса, а значит и более качественные эмбеддинги.\n",
        "\n",
        "Схема:\n",
        "```\n",
        "[Изображение] → [Бэкбон] → [ЭМБЕДДИНГ] → [ArcFace] → [Логиты] → [CE Loss]\n",
        "                    │                        │           │          \n",
        "                   CNN                   Нормализация   Оценки\n",
        "                                          + Angular    для всех\n",
        "                                            Margin     классов\n",
        "```\n",
        "\n",
        "Для получения качественных эмбеддингов после обучения ArcFace-слой больше не нужен, и его обычно обрезают. Он нужен был только обучения модели, и поэтому часто ArcFace называю именно лоссом. Но стоит всегда держать в голове, что это некоторое упрощение, которое нужно лишь для того, чтобы проще формулировать мысли."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXoblo49vDjP"
      },
      "source": [
        "**Доп. литература по ArcFace Loss:**\n",
        "\n",
        "Оригинальная статья: https://arxiv.org/pdf/1801.07698.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSnVw2zNrjpn"
      },
      "source": [
        "## Другие лоссы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdnYR55ZXOzx"
      },
      "source": [
        "Кроме ArcFace, есть еще много разных вариантов лоссов для задачи Face Recognition. Некоторые из них можно найти, например, [тут](https://openaccess.thecvf.com/content_CVPRW_2020/papers/w48/Hsu_A_Comprehensive_Study_on_Loss_Functions_for_Cross-Factor_Face_Recognition_CVPRW_2020_paper.pdf). Вы можете попробовать реализовать другие лосс-функции в этом проекте в качестве дополнительного задания.\n",
        "\n",
        "Кроме этого, можно миксовать лосс-функции. Например, обучать нейросеть на сумме ArcFace и TripletLoss. Иногда так выходит лучше, чем если обучать на каком-то одном лоссе."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pT4nsFZyivfC"
      },
      "source": [
        "# Датасет"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loDtEBkUizfC"
      },
      "source": [
        "В качестве датасета нужно использовать картинки из CelebA, выровненные при помощи своей модели из задания 1. Очень желательно их еще кропнуть таким образом, чтобы нейросети поступали на вход преимущественно только лица без какого либо фона, частей тела и прочего.\n",
        "\n",
        "Если планируете делать дополнительное задание на Identificaton rate metric, то **обязательно разбейте заранее датасет на train/val или train/val/test.** Это нужно сделать не только на уровне кода, а на уровне папок, чтобы точно знать, на каких картинках модель обучалась, а на каких нет. Лучше заранее почитайте [ноутбук с заданием](https://colab.research.google.com/drive/15zuNdOupRFnG7oE-rFj9FsjoNTK6DYn5)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhF-n904jYJz"
      },
      "source": [
        "# План заданий"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqmhb66-jhaK"
      },
      "source": [
        "Итак, вот, что от вас требуется в этом задании:\n",
        "\n",
        "* Выбрать модель (или несколько моделей) для обучения. Можно брать предобученные на ImageNet, но нельзя использовать модели, предобученные на задачу распознавания лиц.\n",
        "* Обучить эту модель (модели) на CE loss. Добиться accuracy > 0.7.\n",
        "* Реализовать ArcFace loss.\n",
        "* Обучить модель (модели) на ArcFace loss. Добиться accuracy > 0.7.\n",
        "* Написать небольшой отчет по обучению, сравнить CE loss и ArcFace loss.\n",
        "\n",
        "**P.S. Не забывайте сохранять модели после обучения**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zU9JhrEwNd6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fLHokvA6Nd0g"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}