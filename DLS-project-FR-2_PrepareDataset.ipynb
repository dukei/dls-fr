{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dukei/dls-fr/blob/master/DLS-project-FR-2_PrepareDataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-tZoxywJ1I0"
      },
      "source": [
        "# Отбор примеров в датасет для распознавания"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pT4nsFZyivfC"
      },
      "source": [
        "# Датасет"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loDtEBkUizfC"
      },
      "source": [
        "В качестве датасета нужно использовать картинки из CelebA, выровненные при помощи своей модели из задания 1. Очень желательно их еще кропнуть таким образом, чтобы нейросети поступали на вход преимущественно только лица без какого либо фона, частей тела и прочего.\n",
        "\n",
        "Если планируете делать дополнительное задание на Identificaton rate metric, то **обязательно разбейте заранее датасет на train/val или train/val/test.** Это нужно сделать не только на уровне кода, а на уровне папок, чтобы точно знать, на каких картинках модель обучалась, а на каких нет. Лучше заранее почитайте [ноутбук с заданием](https://colab.research.google.com/drive/15zuNdOupRFnG7oE-rFj9FsjoNTK6DYn5)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Итак, оказалось, что датасет, подготовленный для распознавания точек лица не слишком подходит для распознавания лиц. Потому что для распознавания лиц нужно набрать в тренировочный датасет для каждого человека несколько изображений (лучше 5+), в валидационный - других и немножечко тех же людей, но для каждого можно пару изображений. А для тестового вообще лучше совсем других людей, но тоже по паре изображений.\n",
        "\n",
        "Поэтому в этом ноутбуке сделаем новый выбор файлов в датасет для распознавания"
      ],
      "metadata": {
        "id": "GxzaRuez93cM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gdown\n",
        "\n",
        "# Загружаем файл с identity\n",
        "if not os.path.exists('celeba_dataset/identity.txt'):\n",
        "    os.makedirs('celeba_dataset', exist_ok=True)\n",
        "\n",
        "    gdown.download(\"https://drive.google.com/file/d/1_ee_0u7vcNLOfNLegJRHmolfH5ICW-XS/view\", 'celeba_dataset/identity.txt', fuzzy=True)"
      ],
      "metadata": {
        "id": "zU9JhrEwNd6O"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "identity_df = pd.read_csv('celeba_dataset/identity.txt',\n",
        "                           sep=' ', skipinitialspace=True,\n",
        "                           names=['image_id','identity'])\n",
        "\n",
        "identity_df"
      ],
      "metadata": {
        "id": "fLHokvA6Nd0g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "2a6bdabf-7199-4656-b25a-3bae14d787b2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          image_id  identity\n",
              "0       000001.jpg      2880\n",
              "1       000002.jpg      2937\n",
              "2       000003.jpg      8692\n",
              "3       000004.jpg      5805\n",
              "4       000005.jpg      9295\n",
              "...            ...       ...\n",
              "202594  202595.jpg      9761\n",
              "202595  202596.jpg      7192\n",
              "202596  202597.jpg      9852\n",
              "202597  202598.jpg      5570\n",
              "202598  202599.jpg     10101\n",
              "\n",
              "[202599 rows x 2 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>identity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000001.jpg</td>\n",
              "      <td>2880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000002.jpg</td>\n",
              "      <td>2937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000003.jpg</td>\n",
              "      <td>8692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000004.jpg</td>\n",
              "      <td>5805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000005.jpg</td>\n",
              "      <td>9295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202594</th>\n",
              "      <td>202595.jpg</td>\n",
              "      <td>9761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202595</th>\n",
              "      <td>202596.jpg</td>\n",
              "      <td>7192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202596</th>\n",
              "      <td>202597.jpg</td>\n",
              "      <td>9852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202597</th>\n",
              "      <td>202598.jpg</td>\n",
              "      <td>5570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202598</th>\n",
              "      <td>202599.jpg</td>\n",
              "      <td>10101</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>202599 rows × 2 columns</p>\n",
              "</div>"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "identity_df",
              "repr_error": "No module named 'httplib2'"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import kagglehub\n",
        "import json\n",
        "\n",
        "dataset_name = 'kevinpatel04/celeba-original-wild-images'\n",
        "dataset_path = './celeba_dataset/'\n",
        "\n",
        "source_dir = kagglehub.dataset_download(dataset_name)\n",
        "source_dir\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jdSf6XBUrUZ",
        "outputId": "9d86aa70-e201-4636-cce8-1e9566fe9bc9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/home/dukei/.cache/kagglehub/datasets/kevinpatel04/celeba-original-wild-images/versions/1'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_distinct_identities_overall = identity_df['identity'].nunique()\n",
        "print(f\"Total number of distinct identities in the original identity_df: {num_distinct_identities_overall}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUly7hllYNci",
        "outputId": "d7f920bd-abb9-4763-e948-d1fa6332187d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of distinct identities in the original identity_df: 10177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f30e3365"
      },
      "source": [
        "### Число разных людей и их изображений\n",
        "\n",
        "Посмотрим, сколько людей есть с каким числом изображений"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d0bfa7b",
        "outputId": "b6d01281-0d30-4aa3-db2d-a8d3fa59fb91"
      },
      "source": [
        "# Count the number of images per identity in the original identity_df\n",
        "original_identity_counts = identity_df['identity'].value_counts().reset_index()\n",
        "original_identity_counts.columns = ['identity', 'count']\n",
        "\n",
        "# Number of identities with exactly 1 image\n",
        "num_identities_1_image_orig = len(original_identity_counts[original_identity_counts['count'] == 1])\n",
        "print(f\"Number of identities with exactly 1 image (in original identity_df): {num_identities_1_image_orig}\")\n",
        "\n",
        "# Number of identities with exactly 2 images\n",
        "num_identities_2_images_orig = len(original_identity_counts[original_identity_counts['count'] == 2])\n",
        "print(f\"Number of identities with exactly 2 images (in original identity_df): {num_identities_2_images_orig}\")\n",
        "\n",
        "# Number of identities with exactly 2 images\n",
        "num_identities_3_images_orig = len(original_identity_counts[original_identity_counts['count'] == 3])\n",
        "print(f\"Number of identities with exactly 32 images (in original identity_df): {num_identities_3_images_orig}\")\n",
        "\n",
        "# Number of identities with exactly 4 images\n",
        "num_identities_4_images_orig = len(original_identity_counts[original_identity_counts['count'] == 4])\n",
        "print(f\"Number of identities with exactly 4 images (in original identity_df): {num_identities_4_images_orig}\")\n",
        "\n",
        "# Number of identities with 5 or more images\n",
        "num_identities_5_plus_orig = len(original_identity_counts[original_identity_counts['count'] >= 5])\n",
        "print(f\"Number of identities with 5 or more images (in original identity_df): {num_identities_5_plus_orig}\")\n",
        "\n",
        "\n",
        "# Number of identities with 3 or more images\n",
        "num_identities_9_plus_orig = len(original_identity_counts[original_identity_counts['count'] >= 9])\n",
        "print(f\"Number of identities with 9 or more images (in original identity_df): {num_identities_9_plus_orig}\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of identities with exactly 1 image (in original identity_df): 44\n",
            "Number of identities with exactly 2 images (in original identity_df): 324\n",
            "Number of identities with exactly 32 images (in original identity_df): 245\n",
            "Number of identities with exactly 4 images (in original identity_df): 221\n",
            "Number of identities with 5 or more images (in original identity_df): 9343\n",
            "Number of identities with 9 or more images (in original identity_df): 8556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Людей с большим числом изображений достаточно. Поэтому дадим Gemini задачу сформировать нам датасет следующим образом:\n",
        "\n",
        "Среди identity, у которых 5 и более изображений, отбери 5000 identity с наиболее разнообразным набором свойств из celeba_dataset/selected_attributes.csv. Это будет тренировочный набор, в который надо включить по 5 случайных изображений этих identity - это будет тренировочный датасет.\n",
        "\n",
        "Далее отбери 800 identity с 2+ изображений из оставшихся identity также с наиболее разнообразным набором атрибутов и возьми каждому по 2 случайных изображения - это часть валидационного датасета. Возьми также 200 identity из числа, отобранного в ранее в тренировочный датасет, у которых было 7+ изображений. И включи 2 их случайных изображения, не включенные до этого в тренировочный датасет - в валидационный.\n",
        "\n",
        "Для тестового датасета возьми 1000 из оставшихся identity с 2+ изображениями, с наиболее равномерным распределением атрибутов и добавь по 2 их случайных изображения в тестовый датасет.\n",
        "\n",
        "Разнообразие обеспечь кластеризацией по комбинации атрибутов - разбей на 200 кластеров и набирай identity из них равномерно."
      ],
      "metadata": {
        "id": "lefWCl8j_XGW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adf7f2bc"
      },
      "source": [
        "# Task\n",
        "Load the `list_attr_celeba.csv` from `source_dir` into a Pandas DataFrame, then merge this attribute data with `identity_df` to create a comprehensive DataFrame for image selection and clustering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c9d8228"
      },
      "source": [
        "## Load and Prepare Attribute Data\n",
        "\n",
        "### Subtask:\n",
        "Load the `list_attr_celeba.csv` from `source_dir` into a Pandas DataFrame. Merge this attribute data with the original `identity_df` to link all images, identities, and their attributes. We will use this merged data for clustering and image selection, independent of the `aligned_faces_data` for now.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2412884c"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to construct the full file path for `list_attr_celeba.csv` and then load it into a Pandas DataFrame. I will use `os.path.join` for path construction and `pd.read_csv` for loading, ensuring proper parsing of the space-separated format. Then, I will convert the attribute values to integers and merge with `identity_df`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f268b6c",
        "outputId": "db2cfdb7-8564-42ec-bae1-e029dced3901"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Construct the full file path\n",
        "attributes_file_name = 'list_attr_celeba.csv'\n",
        "attributes_file_path = os.path.join(source_dir, attributes_file_name)\n",
        "\n",
        "# 2. Load the CSV file into a Pandas DataFrame\n",
        "# Based on inspection of the 'attributes_df' variable state, the file is comma-separated.\n",
        "attributes_df = pd.read_csv(attributes_file_path, sep=',')\n",
        "\n",
        "# The first column is usually 'image_id' and the rest are attribute names. Let's verify and rename if necessary.\n",
        "# Assuming the first column is indeed the image filename after correct parsing.\n",
        "# The first column is unnamed by default when sep=',' is used if it's not explicitly named in the header.\n",
        "# Let's inspect the columns after loading.\n",
        "# If the first column is not named 'image_id', rename it. (No need, the file has a header already)\n",
        "\n",
        "# Ensure the 'image_id' column is the first column as expected and has the correct name.\n",
        "# The actual header of list_attr_celeba.csv usually has 'image_id' or no name for the first column.\n",
        "# Let's check the column names:\n",
        "# If the first column is not named 'image_id', we'll assume it's the first actual data column and it should be.\n",
        "if attributes_df.columns[0] != 'image_id':\n",
        "    # This part might need adjustment if the header structure is different\n",
        "    # However, for CelebA list_attr_celeba.csv, the first column is typically not part of the 'attributes' header\n",
        "    # but is implicitly the image file name. Let's assume the first column *is* 'image_id' and the rest are attributes.\n",
        "    # If the file format is 'image_id,attr1,attr2,...' with a header line of 'attr1,attr2,...' (without image_id in header):\n",
        "    # pd.read_csv might load the first column as unnamed. We need to handle this.\n",
        "    # Let's check the first column name after initial load. If it's an attribute, something is wrong.\n",
        "    # A common issue is the header not containing 'image_id' for the first column.\n",
        "    # To ensure 'image_id' is the first column name:\n",
        "    current_cols = attributes_df.columns.tolist()\n",
        "    if current_cols[0] != 'image_id':\n",
        "        new_cols = ['image_id'] + current_cols[1:]\n",
        "        attributes_df.columns = new_cols\n",
        "\n",
        "\n",
        "# 3. Convert the attribute values from '1' to integer 1 and '-1' to integer -1\n",
        "# Identify attribute columns (all except 'image_id')\n",
        "attribute_cols = [col for col in attributes_df.columns if col != 'image_id']\n",
        "for col in attribute_cols:\n",
        "    attributes_df[col] = attributes_df[col].astype(int)\n",
        "\n",
        "# 4. Merge with identity_df\n",
        "merged_df = pd.merge(identity_df, attributes_df, on='image_id', how='inner')\n",
        "\n",
        "# 5. Display the first few rows and information of the merged_df\n",
        "print(\"First 5 rows of merged_df:\")\n",
        "print(merged_df.head())\n",
        "print(\"\\nInformation about merged_df:\")\n",
        "merged_df.info()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of merged_df:\n",
            "     image_id  identity  5_o_Clock_Shadow  Arched_Eyebrows  Attractive  \\\n",
            "0  000001.jpg      2880                -1                1           1   \n",
            "1  000002.jpg      2937                -1               -1          -1   \n",
            "2  000003.jpg      8692                -1               -1          -1   \n",
            "3  000004.jpg      5805                -1               -1           1   \n",
            "4  000005.jpg      9295                -1                1           1   \n",
            "\n",
            "   Bags_Under_Eyes  Bald  Bangs  Big_Lips  Big_Nose  ...  Sideburns  Smiling  \\\n",
            "0               -1    -1     -1        -1        -1  ...         -1        1   \n",
            "1                1    -1     -1        -1         1  ...         -1        1   \n",
            "2               -1    -1     -1         1        -1  ...         -1       -1   \n",
            "3               -1    -1     -1        -1        -1  ...         -1       -1   \n",
            "4               -1    -1     -1         1        -1  ...         -1       -1   \n",
            "\n",
            "   Straight_Hair  Wavy_Hair  Wearing_Earrings  Wearing_Hat  Wearing_Lipstick  \\\n",
            "0              1         -1                 1           -1                 1   \n",
            "1             -1         -1                -1           -1                -1   \n",
            "2             -1          1                -1           -1                -1   \n",
            "3              1         -1                 1           -1                 1   \n",
            "4             -1         -1                -1           -1                 1   \n",
            "\n",
            "   Wearing_Necklace  Wearing_Necktie  Young  \n",
            "0                -1               -1      1  \n",
            "1                -1               -1      1  \n",
            "2                -1               -1      1  \n",
            "3                 1               -1      1  \n",
            "4                -1               -1      1  \n",
            "\n",
            "[5 rows x 42 columns]\n",
            "\n",
            "Information about merged_df:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 202599 entries, 0 to 202598\n",
            "Data columns (total 42 columns):\n",
            " #   Column               Non-Null Count   Dtype \n",
            "---  ------               --------------   ----- \n",
            " 0   image_id             202599 non-null  object\n",
            " 1   identity             202599 non-null  int64 \n",
            " 2   5_o_Clock_Shadow     202599 non-null  int64 \n",
            " 3   Arched_Eyebrows      202599 non-null  int64 \n",
            " 4   Attractive           202599 non-null  int64 \n",
            " 5   Bags_Under_Eyes      202599 non-null  int64 \n",
            " 6   Bald                 202599 non-null  int64 \n",
            " 7   Bangs                202599 non-null  int64 \n",
            " 8   Big_Lips             202599 non-null  int64 \n",
            " 9   Big_Nose             202599 non-null  int64 \n",
            " 10  Black_Hair           202599 non-null  int64 \n",
            " 11  Blond_Hair           202599 non-null  int64 \n",
            " 12  Blurry               202599 non-null  int64 \n",
            " 13  Brown_Hair           202599 non-null  int64 \n",
            " 14  Bushy_Eyebrows       202599 non-null  int64 \n",
            " 15  Chubby               202599 non-null  int64 \n",
            " 16  Double_Chin          202599 non-null  int64 \n",
            " 17  Eyeglasses           202599 non-null  int64 \n",
            " 18  Goatee               202599 non-null  int64 \n",
            " 19  Gray_Hair            202599 non-null  int64 \n",
            " 20  Heavy_Makeup         202599 non-null  int64 \n",
            " 21  High_Cheekbones      202599 non-null  int64 \n",
            " 22  Male                 202599 non-null  int64 \n",
            " 23  Mouth_Slightly_Open  202599 non-null  int64 \n",
            " 24  Mustache             202599 non-null  int64 \n",
            " 25  Narrow_Eyes          202599 non-null  int64 \n",
            " 26  No_Beard             202599 non-null  int64 \n",
            " 27  Oval_Face            202599 non-null  int64 \n",
            " 28  Pale_Skin            202599 non-null  int64 \n",
            " 29  Pointy_Nose          202599 non-null  int64 \n",
            " 30  Receding_Hairline    202599 non-null  int64 \n",
            " 31  Rosy_Cheeks          202599 non-null  int64 \n",
            " 32  Sideburns            202599 non-null  int64 \n",
            " 33  Smiling              202599 non-null  int64 \n",
            " 34  Straight_Hair        202599 non-null  int64 \n",
            " 35  Wavy_Hair            202599 non-null  int64 \n",
            " 36  Wearing_Earrings     202599 non-null  int64 \n",
            " 37  Wearing_Hat          202599 non-null  int64 \n",
            " 38  Wearing_Lipstick     202599 non-null  int64 \n",
            " 39  Wearing_Necklace     202599 non-null  int64 \n",
            " 40  Wearing_Necktie      202599 non-null  int64 \n",
            " 41  Young                202599 non-null  int64 \n",
            "dtypes: int64(41), object(1)\n",
            "memory usage: 64.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ad400af"
      },
      "source": [
        "## Calculate Original Identity Counts and Filter Candidates\n",
        "\n",
        "### Subtask:\n",
        "Calculate the number of images for each identity based on the *full* `merged_df` to determine the total pool of identities with 2, 5, or 7+ images. Filter this pool to identify candidates for training (5+ images), validation (2+ images), and test (2+ images) sets, ensuring sufficient numbers as specified.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "315e33e4"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires grouping the `merged_df` by 'identity' to count images per identity and then filtering these counts to create DataFrames for identities with 5+ images, 2+ images, and 7+ images, finally printing the unique counts for verification.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "422af68a",
        "outputId": "12419f18-e24d-4712-e3ac-ed3f021553f2"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. Group the merged_df by 'identity' and count the number of images for each identity\n",
        "# The original 'identity_df' already contains all identities and their images.\n",
        "# Since `merged_df` is the result of merging `identity_df` with `attributes_df`,\n",
        "# it contains all original images from `identity_df` that also have attribute data.\n",
        "# We can reuse original_identity_counts from a previous step, as it already has the full counts.\n",
        "# If not available, we'd recalculate it from merged_df:\n",
        "identity_image_counts = merged_df.groupby('identity').size().reset_index(name='count')\n",
        "\n",
        "# 2. Filter for identities with 5 or more images\n",
        "identities_with_5_plus_images = identity_image_counts[identity_image_counts['count'] >= 5]\n",
        "\n",
        "# 3. Filter for identities with 2 or more images\n",
        "identities_with_2_plus_images = identity_image_counts[identity_image_counts['count'] >= 2]\n",
        "\n",
        "# 4. Filter for identities with 7 or more images\n",
        "identities_with_7_plus_images = identity_image_counts[identity_image_counts['count'] >= 7]\n",
        "\n",
        "# 5. Print the number of unique identities found in each filtered DataFrame\n",
        "print(f\"Number of unique identities with 5 or more images: {len(identities_with_5_plus_images)}\")\n",
        "print(f\"Number of unique identities with 2 or more images: {len(identities_with_2_plus_images)}\")\n",
        "print(f\"Number of unique identities with 7 or more images: {len(identities_with_7_plus_images)}\")\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique identities with 5 or more images: 9343\n",
            "Number of unique identities with 2 or more images: 10133\n",
            "Number of unique identities with 7 or more images: 8915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "793290be"
      },
      "source": [
        "## Perform Attribute Clustering on All Relevant Identities\n",
        "\n",
        "### Subtask:\n",
        "For all unique identities from the merged DataFrame (images with attributes and identity info), average their attributes to get a single attribute vector per identity. Then, apply K-Means clustering to group these identities into 200 distinct attribute clusters. This clustering will be used to ensure diversity in selection for all datasets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8ee28d6"
      },
      "source": [
        "**Reasoning**:\n",
        "To prepare for clustering, I will first aggregate the attributes for each identity by calculating the mean of their attribute values, then apply K-Means clustering to group these identities based on their averaged attributes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b48e5717",
        "outputId": "bb437690-15ae-4c50-a731-c0659c611ef8"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "# 1. Group the merged_df by 'identity' and calculate the mean of all attribute columns.\n",
        "#    The attribute columns are all columns except 'image_id' and 'identity'.\n",
        "attribute_cols = [col for col in merged_df.columns if col not in ['image_id', 'identity']]\n",
        "identity_attribute_means = merged_df.groupby('identity')[attribute_cols].mean().reset_index()\n",
        "\n",
        "# 2. Extract only the attribute columns from identity_attribute_means for clustering.\n",
        "X = identity_attribute_means[attribute_cols]\n",
        "\n",
        "# 3. Instantiate a KMeans object with n_clusters=200 and random_state=42.\n",
        "kmeans = KMeans(n_clusters=200, random_state=42, n_init='auto')\n",
        "\n",
        "# 4. Fit the KMeans model to the attribute data.\n",
        "kmeans.fit(X)\n",
        "\n",
        "# 5. Assign the resulting cluster labels back to the identity_attribute_means DataFrame.\n",
        "identity_attribute_means['cluster_label'] = kmeans.labels_\n",
        "\n",
        "print(\"First 5 rows of identity_attribute_means with cluster labels:\")\n",
        "print(identity_attribute_means.head())\n",
        "print(f\"\\nNumber of unique clusters created: {identity_attribute_means['cluster_label'].nunique()}\")\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of identity_attribute_means with cluster labels:\n",
            "   identity  5_o_Clock_Shadow  Arched_Eyebrows  Attractive  Bags_Under_Eyes  \\\n",
            "0         1         -0.310345        -0.931034   -0.448276        -0.172414   \n",
            "1         2         -1.000000        -0.750000    0.750000        -0.750000   \n",
            "2         3         -1.000000        -1.000000    0.360000        -1.000000   \n",
            "3         4         -1.000000        -0.363636    0.909091        -0.909091   \n",
            "4         5         -1.000000        -0.900000    0.500000        -1.000000   \n",
            "\n",
            "   Bald     Bangs  Big_Lips  Big_Nose  Black_Hair  ...   Smiling  \\\n",
            "0  -1.0 -1.000000     -1.00 -0.586207   -0.931034  ... -0.034483   \n",
            "1  -1.0 -0.500000     -1.00 -1.000000   -1.000000  ...  0.000000   \n",
            "2  -1.0 -1.000000     -0.92 -0.200000   -0.760000  ... -0.360000   \n",
            "3  -1.0 -0.636364     -1.00 -0.545455   -1.000000  ...  0.636364   \n",
            "4  -1.0  0.100000     -1.00 -0.600000    0.800000  ...  0.400000   \n",
            "\n",
            "   Straight_Hair  Wavy_Hair  Wearing_Earrings  Wearing_Hat  Wearing_Lipstick  \\\n",
            "0       0.034483  -1.000000         -1.000000    -0.793103         -1.000000   \n",
            "1      -0.250000  -0.750000         -0.750000    -1.000000          0.000000   \n",
            "2      -1.000000  -0.680000         -0.360000     0.440000         -0.760000   \n",
            "3      -0.727273   0.363636         -0.454545    -1.000000          0.909091   \n",
            "4      -0.200000  -1.000000         -1.000000    -0.800000         -0.800000   \n",
            "\n",
            "   Wearing_Necklace  Wearing_Necktie    Young  cluster_label  \n",
            "0         -1.000000            -1.00  0.37931             47  \n",
            "1         -0.750000            -1.00  1.00000             56  \n",
            "2         -0.760000            -0.84  1.00000            156  \n",
            "3         -0.818182            -1.00  1.00000             86  \n",
            "4         -0.800000            -0.90  1.00000            166  \n",
            "\n",
            "[5 rows x 42 columns]\n",
            "\n",
            "Number of unique clusters created: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bcdf543"
      },
      "source": [
        "## Select Training Set Identities and Images\n",
        "\n",
        "### Subtask:\n",
        "Identify identities from the full pool that have 5 or more images. Select 5000 of these identities by sampling uniformly across the 200 attribute clusters to ensure diversity. For each selected training identity, randomly choose 5 unique images from their available images in the merged DataFrame. Store these selections and mark selected identities/images as used.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48df873b"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I will prepare a DataFrame containing identities that have 5 or more images and their cluster labels by merging the `identities_with_5_plus_images` and `identity_attribute_means` DataFrames. This is crucial for the subsequent stratified sampling process across clusters.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05315cbc",
        "outputId": "0cb324fb-d444-4fb4-8510-300fdcba4ddf"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. Prepare a DataFrame containing identities that have 5 or more images, along with their assigned cluster labels.\n",
        "#    This can be done by merging identities_with_5_plus_images and identity_attribute_means on the 'identity' column.\n",
        "identities_for_sampling = pd.merge(\n",
        "    identities_with_5_plus_images[['identity', 'count']],\n",
        "    identity_attribute_means[['identity', 'cluster_label']]\n",
        ").set_index('identity')\n",
        "\n",
        "print(\"Identities with 5+ images and cluster labels (first 5 rows):\")\n",
        "print(identities_for_sampling.head())\n",
        "print(f\"Total identities available for sampling: {len(identities_for_sampling)}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Identities with 5+ images and cluster labels (first 5 rows):\n",
            "          count  cluster_label\n",
            "identity                      \n",
            "1            29             47\n",
            "2             8             56\n",
            "3            25            156\n",
            "4            22             86\n",
            "5            20            166\n",
            "Total identities available for sampling: 9343\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0f47be0"
      },
      "source": [
        "**Reasoning**:\n",
        "Now I will iterate through each cluster to sample the target number of identities, ensuring diversity across clusters, and then for each sampled identity, select 5 unique images and store them while keeping track of used images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10fd512d",
        "outputId": "92aba349-3efb-46c8-c10e-9dc3737de2ff"
      },
      "source": [
        "import random\n",
        "\n",
        "# 2. Determine the target number of identities to sample per cluster (5000 identities / 200 clusters = 25 identities per cluster).\n",
        "#    Handle cases where a cluster has fewer identities than the target.\n",
        "num_identities_to_sample = 5000\n",
        "num_clusters = 200\n",
        "target_per_cluster = num_identities_to_sample // num_clusters\n",
        "\n",
        "sampled_training_identities = []\n",
        "\n",
        "# Group identities by cluster to sample proportionally\n",
        "identities_grouped_by_cluster = identities_for_sampling.groupby('cluster_label')\n",
        "\n",
        "for cluster_label, group in identities_grouped_by_cluster:\n",
        "    # Determine how many identities to sample from this cluster\n",
        "    current_cluster_size = len(group)\n",
        "    num_to_sample_from_cluster = min(target_per_cluster, current_cluster_size)\n",
        "\n",
        "    # Randomly sample identities from the current cluster\n",
        "    sampled_from_this_cluster = group.sample(n=num_to_sample_from_cluster, random_state=42)\n",
        "    sampled_training_identities.append(sampled_from_this_cluster)\n",
        "\n",
        "# Concatenate all sampled identities into a single DataFrame\n",
        "selected_training_identities_df = pd.concat(sampled_training_identities).reset_index()\n",
        "\n",
        "# 4. Initialize an empty dictionary, `train_identities_and_images`, to store the selected training identities and their corresponding image IDs.\n",
        "train_identities_and_images = {}\n",
        "\n",
        "# 5. Initialize an empty set, `used_image_ids`, to keep track of images already selected.\n",
        "used_image_ids = set()\n",
        "\n",
        "# 6. For each identity selected for the training set:\n",
        "for idx, row in selected_training_identities_df.iterrows():\n",
        "    identity_id = row['identity']\n",
        "\n",
        "    # a. Retrieve all image IDs associated with this identity from the `merged_df`.\n",
        "    all_identity_images = merged_df[merged_df['identity'] == identity_id]['image_id'].tolist()\n",
        "\n",
        "    # Filter out images that have already been used by other identities in the training set\n",
        "    available_images = [img for img in all_identity_images if img not in used_image_ids]\n",
        "\n",
        "    # b. Randomly select 5 unique image IDs from this identity's available images.\n",
        "    # Ensure we have at least 5 images to pick from. This was ensured by selecting identities with 5+ images.\n",
        "    if len(available_images) >= 5:\n",
        "        sampled_images = random.sample(available_images, 5)\n",
        "\n",
        "        # c. Store the selected 5 image IDs in the `train_identities_and_images` dictionary, with the identity ID as the key.\n",
        "        train_identities_and_images[identity_id] = sampled_images\n",
        "\n",
        "        # d. Add these 5 image IDs to the `used_image_ids` set to mark them as used.\n",
        "        used_image_ids.update(sampled_images)\n",
        "    else:\n",
        "        # This case should ideally not happen if 'identities_for_sampling' was correctly built with count >= 5\n",
        "        print(f\"Warning: Identity {identity_id} has fewer than 5 available images after filtering used ones. Skipping.\")\n",
        "\n",
        "print(f\"Total unique identities selected for training: {len(train_identities_and_images)}\")\n",
        "print(f\"Total unique images selected for training: {len(used_image_ids)}\")\n",
        "print(\"First 5 entries of train_identities_and_images:\")\n",
        "for i, (identity, images) in enumerate(train_identities_and_images.items()):\n",
        "    if i >= 5: break\n",
        "    print(f\"Identity: {identity}, Images: {images}\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique identities selected for training: 4841\n",
            "Total unique images selected for training: 24205\n",
            "First 5 entries of train_identities_and_images:\n",
            "Identity: 2119, Images: ['170472.jpg', '166806.jpg', '182036.jpg', '168392.jpg', '181507.jpg']\n",
            "Identity: 5286, Images: ['131102.jpg', '003532.jpg', '090202.jpg', '084276.jpg', '113345.jpg']\n",
            "Identity: 191, Images: ['152652.jpg', '089480.jpg', '111245.jpg', '107785.jpg', '006030.jpg']\n",
            "Identity: 6261, Images: ['134867.jpg', '008982.jpg', '130523.jpg', '127951.jpg', '131345.jpg']\n",
            "Identity: 2613, Images: ['000925.jpg', '051999.jpg', '106535.jpg', '079141.jpg', '006456.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9520a4af"
      },
      "source": [
        "## Select Validation Set (Part 1) Identities and Images\n",
        "\n",
        "### Subtask:\n",
        "From identities not yet used (from the full pool) that have 2 or more images, select 800 identities. Sample these 800 identities uniformly from the remaining attribute clusters. For each, randomly select 2 unique images not previously used. Store these selections and mark identities/images as used.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "052e2542"
      },
      "source": [
        "**Reasoning**:\n",
        "I will filter out identities already used in the training set from the potential validation candidates and then merge with cluster labels to prepare for stratified sampling.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "793bb3bc",
        "outputId": "8f19e2e7-5414-47b1-cc58-400d84d6f7da"
      },
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# 1. Filter out identities that were already selected for the training set\n",
        "# Get the list of identities selected for training\n",
        "training_identity_ids = set(train_identities_and_images.keys())\n",
        "\n",
        "# Filter identities_with_2_plus_images to exclude training identities\n",
        "# identities_with_2_plus_images contains identity and count, need to merge with attribute means later for cluster_label\n",
        "remaining_validation_candidates_df = identities_with_2_plus_images[~identities_with_2_plus_images['identity'].isin(training_identity_ids)].copy()\n",
        "\n",
        "# 2. Merge this filtered DataFrame with identity_attribute_means to include the cluster_label\n",
        "validation_identities_for_sampling = pd.merge(\n",
        "    remaining_validation_candidates_df[['identity', 'count']],\n",
        "    identity_attribute_means[['identity', 'cluster_label']],\n",
        "    on='identity',\n",
        "    how='inner'\n",
        ").set_index('identity')\n",
        "\n",
        "print(f\"Total candidate identities for validation (after excluding training): {len(validation_identities_for_sampling)}\")\n",
        "print(\"First 5 rows of validation_identities_for_sampling:\")\n",
        "print(validation_identities_for_sampling.head())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total candidate identities for validation (after excluding training): 5292\n",
            "First 5 rows of validation_identities_for_sampling:\n",
            "          count  cluster_label\n",
            "identity                      \n",
            "10           19            121\n",
            "18           20             66\n",
            "20           19             20\n",
            "22           30             66\n",
            "24           20             27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bb46c67"
      },
      "source": [
        "**Reasoning**:\n",
        "I will proceed with sampling validation identities per cluster and selecting images for them, ensuring that previously used images are not re-selected, as per the remaining instructions of the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aa0a5d2",
        "outputId": "b1b02219-36a3-489a-85b4-096e98de200b"
      },
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "# 3. Determine the target number of identities to sample per cluster\n",
        "num_validation_identities_to_sample = 800\n",
        "num_clusters = 200\n",
        "target_per_cluster_val = num_validation_identities_to_sample // num_clusters\n",
        "\n",
        "# 4. Initialize an empty list to store sampled identities\n",
        "sampled_validation_identities_part1_list = []\n",
        "\n",
        "# Group remaining validation candidates by cluster\n",
        "validation_grouped_by_cluster = validation_identities_for_sampling.groupby('cluster_label')\n",
        "\n",
        "# 5. Iterate through each unique cluster and sample identities\n",
        "for cluster_label, group in validation_grouped_by_cluster:\n",
        "    current_cluster_size = len(group)\n",
        "    num_to_sample_from_cluster = min(target_per_cluster_val, current_cluster_size)\n",
        "\n",
        "    # Randomly sample identities from the current cluster\n",
        "    sampled_from_this_cluster = group.sample(n=num_to_sample_from_cluster, random_state=42)\n",
        "    sampled_validation_identities_part1_list.append(sampled_from_this_cluster)\n",
        "\n",
        "# 6. Concatenate the sampled identities into a single DataFrame\n",
        "selected_validation_identities_part1_df = pd.concat(sampled_validation_identities_part1_list).reset_index()\n",
        "\n",
        "# 7. Initialize an empty dictionary to store the selected validation identities and their corresponding image IDs.\n",
        "val_identities_and_images_part1 = {}\n",
        "\n",
        "# 8. For each identity selected for the validation set:\n",
        "for idx, row in selected_validation_identities_part1_df.iterrows():\n",
        "    identity_id = row['identity']\n",
        "\n",
        "    # a. Retrieve all image IDs associated with this identity from the `merged_df`.\n",
        "    all_identity_images = merged_df[merged_df['identity'] == identity_id]['image_id'].tolist()\n",
        "\n",
        "    # b. Filter these image IDs to exclude any that are already present in the global `used_image_ids` set.\n",
        "    available_images = [img for img in all_identity_images if img not in used_image_ids]\n",
        "\n",
        "    # c. Randomly select 2 unique image IDs from the available (unused) images for this identity.\n",
        "    # Ensure we have at least 2 images to pick from.\n",
        "    if len(available_images) >= 2:\n",
        "        sampled_images = random.sample(available_images, 2)\n",
        "\n",
        "        # d. Store the selected 2 image IDs in the `val_identities_and_images_part1` dictionary.\n",
        "        val_identities_and_images_part1[identity_id] = sampled_images\n",
        "\n",
        "        # e. Add these 2 image IDs to the `used_image_ids` set to mark them as used.\n",
        "        used_image_ids.update(sampled_images)\n",
        "    else:\n",
        "        print(f\"Warning: Identity {identity_id} has fewer than 2 available images after filtering used ones. Skipping for validation.\")\n",
        "\n",
        "# 9. Print the results\n",
        "print(f\"Total unique identities selected for validation (Part 1): {len(val_identities_and_images_part1)}\")\n",
        "print(f\"Total unique images selected for validation (Part 1): {sum(len(v) for v in val_identities_and_images_part1.values())}\")\n",
        "print(\"First 5 entries of val_identities_and_images_part1:\")\n",
        "for i, (identity, images) in enumerate(val_identities_and_images_part1.items()):\n",
        "    if i >= 5: break\n",
        "    print(f\"Identity: {identity}, Images: {images}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique identities selected for validation (Part 1): 752\n",
            "Total unique images selected for validation (Part 1): 1504\n",
            "First 5 entries of val_identities_and_images_part1:\n",
            "Identity: 3094, Images: ['095054.jpg', '033123.jpg']\n",
            "Identity: 3563, Images: ['131344.jpg', '111877.jpg']\n",
            "Identity: 4019, Images: ['031819.jpg', '086204.jpg']\n",
            "Identity: 45, Images: ['126516.jpg', '090391.jpg']\n",
            "Identity: 509, Images: ['099974.jpg', '110368.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29a4239c"
      },
      "source": [
        "## Select Validation Set (Part 2) Identities and Images\n",
        "\n",
        "### Subtask:\n",
        "From the original 5000 training identities, identify those that have 7 or more images available (in the full `identity_df` pool). Select 200 such identities. For each of these 200 identities, randomly select 2 *additional* unique images that were not used in the training set or Validation Part 1. Add these to the validation dataset. Update used images tracker.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55ce5c94"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I will identify the candidate identities for Validation Part 2 by filtering training identities that also have 7+ images. Then, I will merge this with the cluster labels and filter out identities that have already been used, to prepare for stratified sampling.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73bfa959",
        "outputId": "2d82bde7-e0f0-455a-b8f5-caa753adae71"
      },
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# 1. Identify identities from the training set that are also present in identities_with_7_plus_images\n",
        "# Get the list of identities selected for training\n",
        "training_identity_ids = set(train_identities_and_images.keys())\n",
        "\n",
        "# Filter identities_with_7_plus_images to only include those that were part of the initial training set\n",
        "training_identities_with_7_plus_images = identities_with_7_plus_images[identities_with_7_plus_images['identity'].isin(training_identity_ids)].copy()\n",
        "\n",
        "# 2. Merge this candidate pool with identity_attribute_means to include the cluster_label\n",
        "validation_part2_candidates_df = pd.merge(\n",
        "    training_identities_with_7_plus_images[['identity', 'count']],\n",
        "    identity_attribute_means[['identity', 'cluster_label']],\n",
        "    on='identity',\n",
        "    how='inner'\n",
        ").set_index('identity')\n",
        "\n",
        "print(f\"Total candidate identities for Validation Part 2 (from original training set and 7+ images): {len(validation_part2_candidates_df)}\")\n",
        "print(\"First 5 rows of validation_part2_candidates_df:\")\n",
        "print(validation_part2_candidates_df.head())\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total candidate identities for Validation Part 2 (from original training set and 7+ images): 4579\n",
            "First 5 rows of validation_part2_candidates_df:\n",
            "          count  cluster_label\n",
            "identity                      \n",
            "1            29             47\n",
            "2             8             56\n",
            "3            25            156\n",
            "4            22             86\n",
            "5            20            166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "513c5c3e"
      },
      "source": [
        "**Reasoning**:\n",
        "Now I will proceed with sampling the required number of identities from `validation_part2_candidates_df` across clusters, select 2 additional images for each, and update the global `used_image_ids` tracker, as per the remaining instructions of the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da67af33",
        "outputId": "0a845720-ba1a-454b-f5fa-af355c4f873f"
      },
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "# 3. Calculate the target number of identities to sample per cluster\n",
        "num_validation_identities_part2_to_sample = 200\n",
        "num_clusters = 200 # Assuming 200 clusters based on previous step\n",
        "target_per_cluster_val2 = num_validation_identities_part2_to_sample // num_clusters\n",
        "\n",
        "# 4. Initialize an empty list to store sampled identities\n",
        "sampled_validation_identities_part2_list = []\n",
        "\n",
        "# Group remaining validation candidates by cluster\n",
        "validation_part2_grouped_by_cluster = validation_part2_candidates_df.groupby('cluster_label')\n",
        "\n",
        "# 5. Iterate through each unique cluster and sample identities\n",
        "for cluster_label, group in validation_part2_grouped_by_cluster:\n",
        "    current_cluster_size = len(group)\n",
        "    num_to_sample_from_cluster = min(target_per_cluster_val2, current_cluster_size)\n",
        "\n",
        "    # Randomly sample identities from the current cluster\n",
        "    if num_to_sample_from_cluster > 0: # Ensure we don't try to sample 0 items\n",
        "        sampled_from_this_cluster = group.sample(n=num_to_sample_from_cluster, random_state=42)\n",
        "        sampled_validation_identities_part2_list.append(sampled_from_this_cluster)\n",
        "\n",
        "# 6. Concatenate the sampled identities into a single DataFrame\n",
        "if sampled_validation_identities_part2_list:\n",
        "    selected_validation_identities_part2_df = pd.concat(sampled_validation_identities_part2_list).reset_index()\n",
        "else:\n",
        "    selected_validation_identities_part2_df = pd.DataFrame(columns=['identity', 'count', 'cluster_label'])\n",
        "\n",
        "# 7. Initialize an empty dictionary to store the selected validation identities and their corresponding image IDs.\n",
        "val_identities_and_images_part2 = {}\n",
        "\n",
        "# 8. For each identity selected for this part of the validation set:\n",
        "for idx, row in selected_validation_identities_part2_df.iterrows():\n",
        "    identity_id = row['identity']\n",
        "\n",
        "    # a. Retrieve all image IDs associated with this identity from the `merged_df`.\n",
        "    all_identity_images = merged_df[merged_df['identity'] == identity_id]['image_id'].tolist()\n",
        "\n",
        "    # b. Filter these image IDs to exclude any that are already present in the global `used_image_ids` set.\n",
        "    available_images = [img for img in all_identity_images if img not in used_image_ids]\n",
        "\n",
        "    # c. Randomly select 2 unique image IDs from the available (unused) images for this identity.\n",
        "    # Ensure we have at least 2 images to pick from.\n",
        "    if len(available_images) >= 2:\n",
        "        sampled_images = random.sample(available_images, 2)\n",
        "\n",
        "        # d. Store the selected 2 image IDs in the `val_identities_and_images_part2` dictionary.\n",
        "        val_identities_and_images_part2[identity_id] = sampled_images\n",
        "\n",
        "        # e. Add these 2 image IDs to the `used_image_ids` set to mark them as used.\n",
        "        used_image_ids.update(sampled_images)\n",
        "    else:\n",
        "        print(f\"Warning: Identity {identity_id} has fewer than 2 additional available images after filtering used ones. Skipping for Validation Part 2.\")\n",
        "\n",
        "# 9. Print the results\n",
        "print(f\"Total unique identities selected for Validation (Part 2): {len(val_identities_and_images_part2)}\")\n",
        "print(f\"Total unique images selected for Validation (Part 2): {sum(len(v) for v in val_identities_and_images_part2.values())}\")\n",
        "print(\"First 5 entries of val_identities_and_images_part2:\")\n",
        "for i, (identity, images) in enumerate(val_identities_and_images_part2.items()):\n",
        "    if i >= 5: break\n",
        "    print(f\"Identity: {identity}, Images: {images}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique identities selected for Validation (Part 2): 200\n",
            "Total unique images selected for Validation (Part 2): 400\n",
            "First 5 entries of val_identities_and_images_part2:\n",
            "Identity: 5286, Images: ['087933.jpg', '113425.jpg']\n",
            "Identity: 2483, Images: ['051181.jpg', '020285.jpg']\n",
            "Identity: 1936, Images: ['130744.jpg', '024513.jpg']\n",
            "Identity: 2238, Images: ['145753.jpg', '103734.jpg']\n",
            "Identity: 1020, Images: ['084249.jpg', '064422.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56ce6df8"
      },
      "source": [
        "## Select Test Set Identities and Images\n",
        "\n",
        "### Subtask:\n",
        "From identities not yet used (from the full pool) that have 2 or more images, select 1000 identities. Sample these identities uniformly across the remaining attribute clusters to ensure a diverse and representative test set. For each, randomly select 2 unique images not previously used. Store these selections and mark identities/images as used.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c78778d0"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I will gather all identities and images that have already been assigned to the training and validation sets. This involves combining identity IDs from `train_identities_and_images`, `val_identities_and_images_part1`, and `val_identities_and_images_part2` into a single set of `used_identity_ids` and also ensuring the global `used_image_ids` set is updated with all images from these sets. This is crucial for ensuring no overlap between datasets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c57b891",
        "outputId": "d6f56fc5-f1ca-45a2-c893-804e47c6bada"
      },
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# 1. Get the list of identity IDs from the training set, validation set part 1, and validation set part 2.\n",
        "#    Combine these into a single set of used_identity_ids.\n",
        "used_identity_ids = set(train_identities_and_images.keys()) \\\n",
        "                    .union(set(val_identities_and_images_part1.keys())) \\\n",
        "                    .union(set(val_identities_and_images_part2.keys()))\n",
        "\n",
        "# Ensure the global `used_image_ids` set is fully updated with images from all previously selected sets\n",
        "# This should have been done in previous steps, but it's good to re-verify or consolidate if needed.\n",
        "# As per the prompt, `used_image_ids` is already being updated globally.\n",
        "\n",
        "print(f\"Total identities already used in training and validation sets: {len(used_identity_ids)}\")\n",
        "print(f\"Total images already used across all sets: {len(used_image_ids)}\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total identities already used in training and validation sets: 5593\n",
            "Total images already used across all sets: 26109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cce58bae"
      },
      "source": [
        "**Reasoning**:\n",
        "Now I will filter out identities that were already selected for the training and validation sets from the potential test candidates, and then merge with cluster labels to prepare for stratified sampling, as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32457e07",
        "outputId": "abfa3104-2625-42d3-a433-71e355a0a439"
      },
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# 2. Filter identities_with_2_plus_images to exclude all identities present in used_identity_ids.\n",
        "#    This will create remaining_test_candidates_df.\n",
        "remaining_test_candidates_df = identities_with_2_plus_images[\n",
        "    ~identities_with_2_plus_images['identity'].isin(used_identity_ids)\n",
        "].copy()\n",
        "\n",
        "# 3. Merge remaining_test_candidates_df with identity_attribute_means on the 'identity' column\n",
        "#    to include the cluster_label for each remaining candidate.\n",
        "#    Set 'identity' as the index for easier sampling.\n",
        "test_identities_for_sampling = pd.merge(\n",
        "    remaining_test_candidates_df[['identity', 'count']],\n",
        "    identity_attribute_means[['identity', 'cluster_label']],\n",
        "    on='identity',\n",
        "    how='inner'\n",
        ").set_index('identity')\n",
        "\n",
        "print(f\"Total candidate identities for test (after excluding training and validation): {len(test_identities_for_sampling)}\")\n",
        "print(\"First 5 rows of test_identities_for_sampling:\")\n",
        "print(test_identities_for_sampling.head())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total candidate identities for test (after excluding training and validation): 4540\n",
            "First 5 rows of test_identities_for_sampling:\n",
            "          count  cluster_label\n",
            "identity                      \n",
            "10           19            121\n",
            "20           19             20\n",
            "22           30             66\n",
            "38           30             72\n",
            "40           22             12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9da9716e"
      },
      "source": [
        "**Reasoning**:\n",
        "I will proceed with sampling the required number of identities for the test set across clusters, select 2 images for each, and update the global `used_image_ids` tracker, as per the remaining instructions of the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "138a7e0a",
        "outputId": "788117c9-50b4-4447-d457-6cc5c7196294"
      },
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "# 4. Determine the target number of identities to sample per cluster\n",
        "num_test_identities_to_sample = 1000\n",
        "num_clusters = 200 # Assuming 200 clusters based on previous step\n",
        "target_per_cluster_test = num_test_identities_to_sample // num_clusters\n",
        "\n",
        "# 5. Initialize an empty list to store sampled identities\n",
        "sampled_test_identities_list = []\n",
        "\n",
        "# Group remaining test candidates by cluster\n",
        "test_grouped_by_cluster = test_identities_for_sampling.groupby('cluster_label')\n",
        "\n",
        "# 6. Iterate through each unique cluster and sample identities\n",
        "for cluster_label, group in test_grouped_by_cluster:\n",
        "    current_cluster_size = len(group)\n",
        "    num_to_sample_from_cluster = min(target_per_cluster_test, current_cluster_size)\n",
        "\n",
        "    # Randomly sample identities from the current cluster\n",
        "    if num_to_sample_from_cluster > 0: # Ensure we don't try to sample 0 items\n",
        "        sampled_from_this_cluster = group.sample(n=num_to_sample_from_cluster, random_state=42)\n",
        "        sampled_test_identities_list.append(sampled_from_this_cluster)\n",
        "\n",
        "# 7. Concatenate the sampled identities into a single DataFrame\n",
        "if sampled_test_identities_list:\n",
        "    selected_test_identities_df = pd.concat(sampled_test_identities_list).reset_index()\n",
        "else:\n",
        "    selected_test_identities_df = pd.DataFrame(columns=['identity', 'count', 'cluster_label'])\n",
        "\n",
        "# 8. Initialize an empty dictionary to store the selected test identities and their corresponding image IDs.\n",
        "test_identities_and_images = {}\n",
        "\n",
        "# 9. For each identity selected for the test set:\n",
        "for idx, row in selected_test_identities_df.iterrows():\n",
        "    identity_id = row['identity']\n",
        "\n",
        "    # a. Retrieve all image IDs associated with this identity from the `merged_df`.\n",
        "    all_identity_images = merged_df[merged_df['identity'] == identity_id]['image_id'].tolist()\n",
        "\n",
        "    # b. Filter these image IDs to exclude any that are already present in the global `used_image_ids` set.\n",
        "    available_images = [img for img in all_identity_images if img not in used_image_ids]\n",
        "\n",
        "    # c. Randomly select 2 unique image IDs from the available (unused) images for this identity.\n",
        "    # Ensure we have at least 2 images to pick from.\n",
        "    if len(available_images) >= 2:\n",
        "        sampled_images = random.sample(available_images, 2)\n",
        "\n",
        "        # d. Store the selected 2 image IDs in the `test_identities_and_images` dictionary.\n",
        "        test_identities_and_images[identity_id] = sampled_images\n",
        "\n",
        "        # e. Add these 2 image IDs to the `used_image_ids` set to mark them as used.\n",
        "        used_image_ids.update(sampled_images)\n",
        "    else:\n",
        "        print(f\"Warning: Identity {identity_id} has fewer than 2 additional available images after filtering used ones. Skipping for Test Set.\")\n",
        "\n",
        "# 10. Print the results\n",
        "print(f\"Total unique identities selected for Test Set: {len(test_identities_and_images)}\")\n",
        "print(f\"Total unique images selected for Test Set: {sum(len(v) for v in test_identities_and_images.values())}\")\n",
        "print(\"First 5 entries of test_identities_and_images:\")\n",
        "for i, (identity, images) in enumerate(test_identities_and_images.items()):\n",
        "    if i >= 5: break\n",
        "    print(f\"Identity: {identity}, Images: {images}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique identities selected for Test Set: 802\n",
            "Total unique images selected for Test Set: 1604\n",
            "First 5 entries of test_identities_and_images:\n",
            "Identity: 2490, Images: ['172475.jpg', '166181.jpg']\n",
            "Identity: 8845, Images: ['111158.jpg', '019284.jpg']\n",
            "Identity: 7967, Images: ['011942.jpg', '075075.jpg']\n",
            "Identity: 1999, Images: ['165371.jpg', '164405.jpg']\n",
            "Identity: 6699, Images: ['082314.jpg', '144614.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cc67418"
      },
      "source": [
        "# Результаты отбора данных\n",
        "\n",
        "### Основные выводы анализа данных\n",
        "\n",
        "*   **Подготовка данных**: `list_attr_celeba.csv` был успешно загружен и объединен с `identity_df` в `merged_df`. Этот итоговый DataFrame содержит 202 599 записей и 42 столбца (1 для `image_id`, 1 для `identity` и 40 для атрибутов), связывая все изображения, их соответствующие личности и лицевые атрибуты.\n",
        "*   **Количество личностей**: Анализ количества изображений на личность показал:\n",
        "    *   9343 уникальных личности с 5 или более изображениями.\n",
        "    *   10133 уникальных личности с 2 или более изображениями.\n",
        "    *   8915 уникальных личности с 7 или более изображениями.\n",
        "*   **Кластеризация атрибутов**: Кластеризация K-Means была применена к усредненным векторам атрибутов для каждой личности, успешно сгруппировав все уникальные личности в 200 различных кластеров атрибутов, обеспечивая разнообразие для последующей выборки.\n",
        "*   **Выборка обучающего набора**:\n",
        "    *   4841 уникальная личность была выбрана для обучающего набора, отобранная равномерно по 200 кластерам атрибутов из личностей с 5+ изображениями.\n",
        "    *   Всего 24205 уникальных изображений были назначены этим обучающим личностям (по 5 изображений на личность).\n",
        "*   **Выборка валидационного набора (Часть 1)**:\n",
        "    *   752 уникальные личности были выбраны для Валидационного набора Части 1, отобранные равномерно из оставшихся личностей (не в обучающем наборе) с 2+ изображениями.\n",
        "    *   Всего 1504 уникальных изображения были назначены этим личностям (по 2 изображения на личность).\n",
        "*   **Выборка валидационного набора (Часть 2)**:\n",
        "    *   200 уникальных личностей были выбраны для Валидационного набора Части 2. Эти личности были выбраны из исходных обучающих личностей, у которых было 7+ доступных изображений, обеспечивая баланс между кластерами.\n",
        "    *   Всего 400 уникальных изображений были назначены (по 2 дополнительных изображения на личность), которые ранее не использовались.\n",
        "*   **Выборка тестового набора**:\n",
        "    *   802 уникальные личности были выбраны для тестового набора, отобранные равномерно из оставшихся личностей (не в обучающем или валидационном наборах) с 2+ изображениями.\n",
        "    *   Всего 1604 уникальных изображения были назначены этим личностям (по 2 изображения на личность). Процесс выбора строго гарантировал, что все выбранные изображения для тестового набора ранее не использовались."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfa8c91c"
      },
      "source": [
        "# Сохранение датасета\n",
        "\n",
        "Теперь проверим на всякий случай, что у нас датасеты не пересекаются, и сохраним их в папку celeba_dataset/ft"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b172e594",
        "outputId": "6e51911c-b9b3-49d0-a41f-f220dc17a23d"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. Create three empty lists\n",
        "train_data = []\n",
        "val_data = []\n",
        "test_data = []\n",
        "\n",
        "# 2. Populate train_data\n",
        "for identity_id, image_ids in train_identities_and_images.items():\n",
        "    for image_id in image_ids:\n",
        "        train_data.append((image_id, identity_id))\n",
        "\n",
        "# 3. Populate val_data from part1\n",
        "for identity_id, image_ids in val_identities_and_images_part1.items():\n",
        "    for image_id in image_ids:\n",
        "        val_data.append((image_id, identity_id))\n",
        "\n",
        "# 4. Populate val_data from part2\n",
        "for identity_id, image_ids in val_identities_and_images_part2.items():\n",
        "    for image_id in image_ids:\n",
        "        val_data.append((image_id, identity_id))\n",
        "\n",
        "# 5. Populate test_data\n",
        "for identity_id, image_ids in test_identities_and_images.items():\n",
        "    for image_id in image_ids:\n",
        "        test_data.append((image_id, identity_id))\n",
        "\n",
        "# 6. Extract all image IDs into separate sets for each dataset\n",
        "train_image_set = {item[0] for item in train_data}\n",
        "val_image_set = {item[0] for item in val_data}\n",
        "test_image_set = {item[0] for item in test_data}\n",
        "\n",
        "# 7. Check for overlaps:\n",
        "# a. Intersection of train_image_set and val_image_set\n",
        "overlap_train_val = train_image_set.intersection(val_image_set)\n",
        "\n",
        "# b. Intersection of train_image_set and test_image_set\n",
        "overlap_train_test = train_image_set.intersection(test_image_set)\n",
        "\n",
        "# c. Intersection of val_image_set and test_image_set\n",
        "overlap_val_test = val_image_set.intersection(test_image_set)\n",
        "\n",
        "# 8. Print the sizes of the image sets\n",
        "print(f\"Total unique images in Training set: {len(train_image_set)}\")\n",
        "print(f\"Total unique images in Validation set: {len(val_image_set)}\")\n",
        "print(f\"Total unique images in Test set: {len(test_image_set)}\")\n",
        "\n",
        "# 9. Print the results of the intersection checks\n",
        "print(f\"\\nOverlap between Training and Validation sets: {len(overlap_train_val)} images\")\n",
        "print(f\"Overlap between Training and Test sets: {len(overlap_train_test)} images\")\n",
        "print(f\"Overlap between Validation and Test sets: {len(overlap_val_test)} images\")\n",
        "\n",
        "# Raise an assertion error if any intersection is not empty\n",
        "assert len(overlap_train_val) == 0, f\"Duplicate images found between Training and Validation sets: {overlap_train_val}\"\n",
        "assert len(overlap_train_test) == 0, f\"Duplicate images found between Training and Test sets: {overlap_train_test}\"\n",
        "assert len(overlap_val_test) == 0, f\"Duplicate images found between Validation and Test sets: {overlap_val_test}\"\n",
        "\n",
        "print(\"\\nAll datasets are mutually exclusive, no image ID overlaps found.\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique images in Training set: 24205\n",
            "Total unique images in Validation set: 1904\n",
            "Total unique images in Test set: 1604\n",
            "\n",
            "Overlap between Training and Validation sets: 0 images\n",
            "Overlap between Training and Test sets: 0 images\n",
            "Overlap between Validation and Test sets: 0 images\n",
            "\n",
            "All datasets are mutually exclusive, no image ID overlaps found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bfbd540"
      },
      "source": [
        "Датасеты не пересекаются, отлично, сохраняем в файлы\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b97f8611",
        "outputId": "5a0d0a99-18d1-41f8-a213-aa9849a6bda6"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# 10. Convert the lists into Pandas DataFrames\n",
        "train_df = pd.DataFrame(train_data, columns=['image_id', 'identity'])\n",
        "val_df = pd.DataFrame(val_data, columns=['image_id', 'identity'])\n",
        "test_df = pd.DataFrame(test_data, columns=['image_id', 'identity'])\n",
        "\n",
        "# 11. Create the output directory if it doesn't exist\n",
        "output_dir = os.path.join('celeba_dataset', 'fr')\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# 12. Save each DataFrame to a CSV file in the specified directory\n",
        "train_output_path = os.path.join(output_dir, 'fr_train_identity.csv')\n",
        "val_output_path = os.path.join(output_dir, 'fr_val_identity.csv')\n",
        "test_output_path = os.path.join(output_dir, 'fr_test_identity.csv')\n",
        "\n",
        "train_df.to_csv(train_output_path, index=False)\n",
        "val_df.to_csv(val_output_path, index=False)\n",
        "test_df.to_csv(test_output_path, index=False)\n",
        "\n",
        "print(f\"Training dataset saved to: {train_output_path}\")\n",
        "print(f\"Validation dataset saved to: {val_output_path}\")\n",
        "print(f\"Test dataset saved to: {test_output_path}\")\n",
        "\n",
        "print(\"First 5 rows of Training DataFrame:\")\n",
        "print(train_df.head())\n",
        "print(\"\\nFirst 5 rows of Validation DataFrame:\")\n",
        "print(val_df.head())\n",
        "print(\"\\nFirst 5 rows of Test DataFrame:\")\n",
        "print(test_df.head())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset saved to: celeba_dataset/fr/fr_train_identity.csv\n",
            "Validation dataset saved to: celeba_dataset/fr/fr_val_identity.csv\n",
            "Test dataset saved to: celeba_dataset/fr/fr_test_identity.csv\n",
            "First 5 rows of Training DataFrame:\n",
            "     image_id  identity\n",
            "0  170472.jpg      2119\n",
            "1  166806.jpg      2119\n",
            "2  182036.jpg      2119\n",
            "3  168392.jpg      2119\n",
            "4  181507.jpg      2119\n",
            "\n",
            "First 5 rows of Validation DataFrame:\n",
            "     image_id  identity\n",
            "0  095054.jpg      3094\n",
            "1  033123.jpg      3094\n",
            "2  131344.jpg      3563\n",
            "3  111877.jpg      3563\n",
            "4  031819.jpg      4019\n",
            "\n",
            "First 5 rows of Test DataFrame:\n",
            "     image_id  identity\n",
            "0  172475.jpg      2490\n",
            "1  166181.jpg      2490\n",
            "2  111158.jpg      8845\n",
            "3  019284.jpg      8845\n",
            "4  011942.jpg      7967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b012c6b"
      },
      "source": [
        "## Сводка:\n",
        "\n",
        "### Основные выводы анализа данных\n",
        "*   Обучающий набор данных содержит 24 205 уникальных изображений, валидационный набор данных содержит 1904 уникальных изображения, а тестовый набор данных состоит из 1604 уникальных изображений.\n",
        "*   Все наборы данных (обучающий, валидационный и тестовый) являются взаимоисключающими, с 0 изображениями, перекрывающимися между обучающим и валидационным наборами, 0 между обучающим и тестовым наборами и 0 между валидационным и тестовым наборами.\n",
        "*   Отдельные CSV-файлы с именами `fr_train_identity.csv`, `fr_val_identity.csv` и `fr_test_identity.csv` были успешно созданы и сохранены в директории `celeba_dataset/fr/`, каждый из которых содержит столбцы `image_id` и `identity`.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}